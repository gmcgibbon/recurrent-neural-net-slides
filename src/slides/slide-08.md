## Training

ANNs rely on backpropagation to learn by minimizing error. RNN training uses a backprop variant called Backpropagation Through Time (BPTT). BPTT allows backprop to take recurrent complexities into account.

Vertical:

## Backprop in Feedforward Neural Networks

![ANN Backprop Diagram](https://i.stack.imgur.com/H1KsG.png)

Vertical:

## Backprop in Recurrent Neural Networks

![RNN Backprop Diagram](https://pbs.twimg.com/media/CQ0CJtwUkAAL__H.png)

Vertical:

## Backprop in Practice

In practice, you don't need to worry about your backpropagation implementation. It is taken care of for you behind the scenes when using frameworks like TensorFlow, Keras, or CNTK.
